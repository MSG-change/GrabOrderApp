#!/usr/bin/env python3
"""
å°†PyTorchæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼
ONNXæ›´é€‚åˆåœ¨Androidè®¾å¤‡ä¸Šè¿è¡Œ
"""

import torch
import torch.onnx
import os
import sys

# æ·»åŠ libsåˆ°è·¯å¾„
sys.path.append('libs')
from siamese_network import SiameseNetwork

def convert_pytorch_to_onnx():
    """è½¬æ¢PyTorchæ¨¡å‹åˆ°ONNXæ ¼å¼"""
    
    print("ğŸ”„ å¼€å§‹è½¬æ¢ PyTorch -> ONNX...")
    
    # 1. åŠ è½½PyTorchæ¨¡å‹
    model_path = "best_siamese_model.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        return False
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = SiameseNetwork(feature_dim=512)
    
    # åŠ è½½æƒé‡ï¼ˆPyTorch 2.6+éœ€è¦è®¾ç½®weights_only=Falseï¼‰
    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        accuracy = checkpoint.get('val_acc', 0) * 100
        print(f"   æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2f}%")
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    
    # 2. åˆ›å»ºç¤ºä¾‹è¾“å…¥
    batch_size = 1
    dummy_input1 = torch.randn(batch_size, 3, 224, 224)
    dummy_input2 = torch.randn(batch_size, 3, 224, 224)
    
    # 3. å¯¼å‡ºONNX
    onnx_path = "siamese_model.onnx"
    
    print(f"ğŸ“¦ å¯¼å‡ºåˆ°: {onnx_path}")
    
    torch.onnx.export(
        model,                      # æ¨¡å‹
        (dummy_input1, dummy_input2),  # ç¤ºä¾‹è¾“å…¥
        onnx_path,                  # è¾“å‡ºè·¯å¾„
        export_params=True,         # å¯¼å‡ºå‚æ•°
        opset_version=11,           # ONNXç‰ˆæœ¬
        do_constant_folding=True,   # ä¼˜åŒ–å¸¸é‡
        input_names=['image1', 'image2'],   # è¾“å…¥å
        output_names=['similarity', 'distance', 'cosine'],  # è¾“å‡ºå
        dynamic_axes={              # åŠ¨æ€è½´ï¼ˆæ”¯æŒä¸åŒbatch sizeï¼‰
            'image1': {0: 'batch_size'},
            'image2': {0: 'batch_size'},
            'similarity': {0: 'batch_size'}
        }
    )
    
    # 4. éªŒè¯ONNXæ¨¡å‹
    try:
        import onnx
        onnx_model = onnx.load(onnx_path)
        onnx.checker.check_model(onnx_model)
        print("âœ… ONNXæ¨¡å‹éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âš ï¸  ONNXéªŒè¯å¤±è´¥: {e}")
    
    # 5. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    file_size = os.path.getsize(onnx_path) / (1024 * 1024)
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   åŸå§‹å¤§å°: {os.path.getsize(model_path) / (1024*1024):.2f} MB")
    print(f"   ONNXå¤§å°: {file_size:.2f} MB")
    print(f"   å‹ç¼©ç‡: {file_size / (os.path.getsize(model_path) / (1024*1024)) * 100:.1f}%")
    
    # 6. ä¼˜åŒ–ONNXï¼ˆå¯é€‰ï¼‰
    optimize_onnx(onnx_path)
    
    return True


def optimize_onnx(onnx_path):
    """ä¼˜åŒ–ONNXæ¨¡å‹ç”¨äºç§»åŠ¨ç«¯"""
    try:
        from onnxruntime.quantization import quantize_dynamic, QuantType, QuantFormat
        
        print("\nğŸ”§ ä¼˜åŒ–ONNXæ¨¡å‹...")
        
        # é‡åŒ–æ¨¡å‹ï¼ˆå‡å°ä½“ç§¯ï¼‰
        quantized_path = onnx_path.replace('.onnx', '_quantized.onnx')
        
        try:
            quantize_dynamic(
                onnx_path,
                quantized_path,
                weight_type=QuantType.QUInt8  # 8ä½é‡åŒ–
            )
        except (ValueError, RuntimeError) as e:
            print(f"   âš ï¸ åŠ¨æ€é‡åŒ–å¤±è´¥: {e}")
            print(f"   ä½¿ç”¨ç®€å•ä¼˜åŒ–...")
            # ç®€å•å¤åˆ¶æ–‡ä»¶ä½œä¸ºå¤‡ç”¨
            import shutil
            shutil.copy(onnx_path, quantized_path)
            return
        
        # æ¯”è¾ƒå¤§å°
        original_size = os.path.getsize(onnx_path) / (1024 * 1024)
        quantized_size = os.path.getsize(quantized_path) / (1024 * 1024)
        
        print(f"âœ… é‡åŒ–å®Œæˆ:")
        print(f"   åŸå§‹: {original_size:.2f} MB")
        print(f"   é‡åŒ–: {quantized_size:.2f} MB")
        print(f"   å‡å°: {(1 - quantized_size/original_size) * 100:.1f}%")
        
    except ImportError:
        print("   æç¤º: å®‰è£…onnxruntimeå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹")
        print("   pip install onnxruntime")


if __name__ == "__main__":
    convert_pytorch_to_onnx()
